{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGRC5vxkF9FH"
   },
   "source": [
    "DATA:\n",
    "\n",
    "Feature variables: SMS message\n",
    "\n",
    "Target Class: message type ( Ham, Spam) \n",
    "\n",
    "1500 sample\n",
    "\n",
    "\n",
    "### 5.1. Setup\n",
    "\n",
    "Install required text processing libraries for the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wES6b5HwF9FJ",
    "outputId": "962c0337-69bd-409c-9f01-eef7bff40849"
   },
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ox8T25dTF9FL"
   },
   "source": [
    "### 5.2. Creating Text Representations\n",
    "\n",
    "Text data needs to be converted to numeric representations before they can be used to train deep learning models. The Spam classification feature data is converted to TF-IDF vectors and the target variable is converted to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDHw0iz-F9FL",
    "outputId": "946abcd0-6ade-42b4-e6c5-d7ab71bd5e2a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#Load Spam Data and review content\n",
    "spam_data = pd.read_csv(\"Spam-Classification.csv\")\n",
    "\n",
    "print(\"\\nLoaded Data :\\n------------------------------------\")\n",
    "print(spam_data.head())\n",
    "\n",
    "#Separate feature and target data\n",
    "spam_classes_raw = spam_data[\"CLASS\"]\n",
    "spam_messages = spam_data[\"SMS\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8keU544AF9FL",
    "outputId": "f5c36cd3-b1b5-428e-a674-5de2bfb69376"
   },
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "\n",
    "#Custom tokenizer to remove stopwords and use lemmatization\n",
    "def customtokenize(str):\n",
    "    #Split string as tokens\n",
    "    tokens=nltk.word_tokenize(str)\n",
    "    #Filter for stopwords\n",
    "    nostop = list(filter(lambda token: token not in stopwords.words('english'), tokens))\n",
    "    #Perform lemmatization\n",
    "    lemmatized=[lemmatizer.lemmatize(word) for word in nostop ]\n",
    "    return lemmatized\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Build a TF-IDF Vectorizer model\n",
    "vectorizer = TfidfVectorizer(tokenizer=customtokenize)\n",
    "\n",
    "#Transform feature input to TF-IDF\n",
    "tfidf=vectorizer.fit_transform(spam_messages)\n",
    "#Convert TF-IDF to numpy array\n",
    "tfidf_array = tfidf.toarray()\n",
    "\n",
    "#Build a label encoder for target variable to convert strings to numeric values.\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "spam_classes = label_encoder.fit_transform(\n",
    "                                spam_classes_raw)\n",
    "\n",
    "#Convert target to one-hot encoding vector\n",
    "spam_classes = tf.keras.utils.to_categorical(spam_classes,2)\n",
    "\n",
    "print(\"TF-IDF Matrix Shape : \", tfidf.shape)\n",
    "print(\"One-hot Encoding Shape : \", spam_classes.shape)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split( tfidf_array, spam_classes, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uu-ZKPpmF9FM"
   },
   "source": [
    "### 5.3. Building and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYoq2HvuF9FM",
    "outputId": "e468bff5-be53-4623-86f7-0d0588403046"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "#Setup Hyper Parameters for building the model\n",
    "NB_CLASSES=2\n",
    "N_HIDDEN=32\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                             input_shape=(X_train.shape[1],),\n",
    "                              name='Hidden-Layer-1',\n",
    "                              activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                              name='Hidden-Layer-2',\n",
    "                              activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "                             name='Output-Layer',\n",
    "                             activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hzHfHZ0qF9FM",
    "outputId": "ad5fabf3-de67-4111-e006-6ad729d36c3d"
   },
   "outputs": [],
   "source": [
    "#Make it verbose so we can see the progress\n",
    "VERBOSE=1\n",
    "\n",
    "#Setup Hyper Parameters for training\n",
    "BATCH_SIZE=256\n",
    "EPOCHS=10\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "print(\"\\nTraining Progress:\\n------------------------------------\")\n",
    "\n",
    "history=model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "print(\"\\nAccuracy during Training :\\n------------------------------------\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history)[\"accuracy\"].plot(figsize=(8, 5))\n",
    "plt.title(\"Accuracy improvements with Epoch\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEvaluation against Test Dataset :\\n------------------------------------\")\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyyyyP9lF9FN"
   },
   "source": [
    "### 5.4. Predicting for Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFsqYNMEF9FN",
    "outputId": "a6dcc34a-bebd-475c-8aa1-ec537079a542"
   },
   "outputs": [],
   "source": [
    "#Predict for multiple samples using batch processing\n",
    "\n",
    "#Convert input into IF-IDF vector using the same vectorizer model\n",
    "predict_tfidf=vectorizer.transform([\"FREE entry to a fun contest\",\n",
    "                                    \"Yup I will come over\"]).toarray()\n",
    "\n",
    "print(predict_tfidf.shape)\n",
    "\n",
    "#Predict using model\n",
    "prediction=np.argmax( model.predict(predict_tfidf), axis=1 )\n",
    "print(\"Prediction Output:\" , prediction)\n",
    "\n",
    "#Print prediction classes\n",
    "print(\"Prediction Classes are \", label_encoder.inverse_transform(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j45rjoryF9FN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
